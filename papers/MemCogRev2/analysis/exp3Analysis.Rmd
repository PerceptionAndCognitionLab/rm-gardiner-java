
```{r get-data, cache = T, message=F, echo = F}
url <- "https://github.com/PerceptionCognitionLab/data1/tree/master/repGardinerJava/exp2/RKN_replication/RKN_exp2/SU"

##Quick fix for some participant IDs giving out to several people
github_page <- read_html(url)
file_nodes <- html_nodes(github_page, ".content .css-truncate-target .js-navigation-open")
file_names <- html_text(file_nodes)
I <- length(file_names) - 1


dat <- batch_read_github(url
                         , extension = "_RKN"
                         , read_fun = read.csv
                         )

# exclusion <- c(0, 1, 999, 998, 551998138)
exclusion <- c(999)
dat <- subset(dat, !(ID %in% exclusion))
I <- I - length(exclusion)
K <- table(dat$ID, dat$test_type)[1]
L <- table(dat$ID, dat$test_type, dat$item_type)[1]
dat$sub <- rep(1:I, each = 2 * K)
dat$rating_resp <- factor(dat$rating_resp, levels = c("S", "U", "N"))
ids <- unique(dat$sub)
dat <- droplevels(dat)
```

```{r data-cleaning, fig.height=4, fig.width=5, echo = F}
# kable(head(dat))

dat$accuracy <- dat$test_type == dat$ON_resp
sub.acc <- tapply(dat$accuracy, dat$sub, mean)
# hist(sub.acc, xlab = "Accuracy", main = "")
# abline(v = mean(sub.acc), lwd = 2, col = "darkred")

performance.crit <- sub.acc > .5
I.clean <- sum(performance.crit) #Number of participants that have above-chance performance.

include <- ids[performance.crit]
dat.clean <- subset(dat, sub %in% include)

props_subj <- plyr::ddply(dat.clean
                    , c("sub", "item_type", "test_type", "rating_resp")
                    , summarise
                    , prop = length(sub)/L
                    , .drop=FALSE)
# res <- table(dat.clean$RK_resp, dat.clean$test_type, dat.clean$item_type)/(I.clean*L)
res <- tapply(props_subj$prop
              , list(props_subj$rating_resp, props_subj$item_type, props_subj$test_type)
              , mean)
```

```{r descriptive-plot, fig.width=6, fig.height=4, fig.cap="Rebuilt figure from Gardiner and Java with data from our Experiment 1.", eval = F}
layout(matrix(1:2, ncol = 2), widths = c(.54, .46))
par(mar = c(5.1, 4.1, 4.1, 2.1))

su <- rep(1:2, 2)
barcols <- c("royalblue", "indianred")

barplot(as.vector(res[2:3,1,])
        , space = c(0.1,0.1, .6, 0.1)
        , col = barcols[su]
        , ylim = c(0, .4)
        , ylab = "Response Probability"
        )
mtext(c("Lure", "Target"), side = 1, line = 1, at = c(1.1, 3.8))
mtext(c("Nonwords"), side = 1, line = 2, at = 2.5)
legend("topleft", legend = c("Remember", "Know"), fill = barcols, bty = "n", cex = .8)


par(mar = c(5.1, 1, 4.1, 2.1))

barplot(as.vector(res[2:3,2,])
        , space = c(0.1,0.1, .6, 0.1)
        , col = barcols[su]
        , ylim = c(0, .4)
        , yaxt = "n"
        )
mtext(c("Lure", "Target"), side = 1, line = 1, at = c(1.1, 3.8))
mtext(c("Words"), side = 1, line = 2, at = 2.5)

```

```{r tabExp2, results="asis", eval = T}
tabres <- tapply(props_subj$prop
              , list(props_subj$item_type, props_subj$rating_resp, props_subj$test_type)
              , mean)

tabres <- rbind(tabres[,,2], tabres[,,1])
tabres <- tabres[c(2, 1, 4, 3), ]
# Item <- rownames(tabres)
# Test <- rep(c("old", "new"), each = 2)
colnames(tabres) <- c("Sure", "Unsure", "New")
rownames(tabres) <- c("Old Word","Old Nonword","New Word", "New Nonword")

# apa_table(round(tabres, 3)
#           , col_spanners = list('Response' = c(2, 4))
#           , caption = "Response proportions in Experiment 2"
#           )
# tabres <- tapply(props_subj$prop
#               , list(props_subj$item_type, props_subj$rating_resp, props_subj$test_type)
#               , mean)
# 
# tabres <- as.data.frame(rbind(tabres[,,2], tabres[,,1]))
# Item <- rownames(tabres)
# Test <- rep(c("old", "new"), each = 2)
# 
# kable(cbind(Test, Item, round(tabres, 3)))
```


```{r, fig.cap="Results from Experiment 1. There is no interaction between item type (i.e. word vs. non-word) and preferred response category (i.e. Remember vs. Know). Error bars show standard errors.", fig.width=8, fig.height=4, eval = F}
# props_subj <- group_by(dat.clean, sub, item_type, test_type, RK_resp) %>% dplyr::summarize(prop = n())
props_subj <- subset(props_subj, rating_resp != "N")

item.labels <- c(
  'nonword' = "Nonword"
  , 'word' = "Word"
)

ggplot(props_subj, aes(x = test_type, y=prop, group = rating_resp, linetype = rating_resp, shape = rating_resp)) +
  stat_summary(fun.data = mean_se, geom = "errorbar", color = "black", width = 0.1, linetype = "solid") + 
  stat_summary(fun.y = mean, geom = "line", color = "black") +
  stat_summary(fun.y = mean, geom = "point", color = "black", size = 2.5) +
  labs(x = "", y = "Response Proportion", linetype = "Response", shape = "Response") +
  coord_cartesian(ylim = c(0, .45)) +
  facet_grid(. ~ item_type, labeller = as_labeller(item.labels))+
  scale_shape_discrete(labels = c("Remember", "Know")) +
  scale_linetype_discrete(labels = c("Remember", "Know")) +
  scale_x_discrete(labels = c("New", "Old")) +
    theme(
      # legend.position = "top"
      legend.key.height = unit(14, "points")
      , legend.key.width = unit(14, "points")
      , legend.key.size = unit(3, 'lines')
      , legend.margin = margin()
      , plot.margin = margin(0, 1, 0, 0, "lines")
    )
```


```{r dat-reformat-2}
freq_subj <- plyr::ddply(dat.clean
                    , c("sub", "item_type", "test_type", "rating_resp")
                    , summarise, freq = length(sub), .drop=FALSE)

psw <- dcast(freq_subj, sub + item_type + test_type ~ rating_resp, fill = 0)

make_y <- function(dat, exp = "rk"){ 
  #vector of 3 values
  #, first = number of remember responses
  #, second = number of know/unsure responses
  #, third = number of new/sure responses
  if(!is.vector(dat)){return("data not in the right format")}
  if(length(dat) !=3){
    return(ifelse(exp == "rk"
                  , "please submit vector with #remember
           , #know and #new responses and column labels R, K and N"
           , "please submit vector with #sure
           , #unsure and #new responses and column labels S, U , and N"))}
  
  ifelse(exp == "rk"
         , (dat['R'] - dat['K'])/sum(dat[c('R', 'K', 'N')])
         , (dat['S'] - dat['U'])/sum(dat[c('S', 'U', 'N')]))
}

y <- apply(psw[,c('S', 'U', 'N')], 1, make_y, exp = "su")

#Recode item-type and test_type into one factor
cond <- with(psw, interaction(item_type, test_type))
#I need level order: ow, onw, nw, nnw
cond <- factor(cond, rev(levels(cond)))

#Recode ID into factor
sub <- as.factor(psw$sub)

dat.all.3 <- cbind(psw, y)
```

```{r design-mat-2, echo = F}
###Design matrices

#Mu
X_u <- matrix(0, nrow = length(y), ncol = 4)
for(i in 1:length(y)){
  X_u[i, as.numeric(cond[i])] <- 1
}

#M0
X_star <- X_u[, 1:3]
X_star[,3] <- X_u[,3] + X_u[,4]

#M_A1
X_A1 <- X_star[, 2:3]
X_A1[,1] <- X_star[,1] + X_star[,2]

#No design matrices for the other two models are needed
#, since they have the same design matrix as M_u
```

```{r estimation-2, echo = F}
###Estimation & Bayes factors for raw models using bayesfactor package
r <- sqrt(2)/(2)

#Mu
gMap <- rep(0, 4)
samples_u <- nWayAOV(y, X_u, gMap, rscale = r
                     , posterior = T, iterations = 100000)
out_u <- nWayAOV(y, X_u, gMap, rscale = r)

#M0
gMap <- rep(0, 3)
samples_star <- nWayAOV(y, X_star, gMap, rscale = r
                        , posterior = T, iterations = 100000)
out_star <- nWayAOV(y, X_star, gMap, rscale = r)

#MA1
gMap <- rep(0, 2)
# samples_A1 <- nWayAOV(y, X_A1, gMap, rscale = 1, posterior = T)
out_A1 <- nWayAOV(y, X_A1, gMap, rscale = r)
```

```{r bayes-factor-2, echo = F}
###Bayes factor computation using encompassing approach Haaf&Rouder

#M0
est.star <- samples_star[,1] + samples_star[, 2:4]
# colMeans(est.star)

##Posterior prob of mu1> mu2
# star <- est.star[,1] > 0 & est.star[,2] < 0
star <- est.star[,1] > est.star[,2]
post.prob.star <- mean(star)

##Prior prob of mu1 > mu2
R <- 1000000
mu.theta.sd <- .5
mu1 <- rnorm(R, 0, mu.theta.sd)
mu2 <- rnorm(R, 0, mu.theta.sd)
# priorstar <- mu1 > 0 & mu2 < 0
priorstar <- mu1 > mu2
prior.prob.star <- mean(priorstar)

#MA2
est.u <- samples_u[,1] + samples_u[, 2:5]
# colMeans(est.u)

##Posterior
a2 <- est.u[,1] > est.u[,2] & est.u[,3] > est.u[,4]
post.prob.a2 <- mean(a2)

##Prior prob
mu1 <- rnorm(R, 0, mu.theta.sd)
mu2 <- rnorm(R, 0, mu.theta.sd)
mu3 <- rnorm(R, 0, mu.theta.sd)
mu4 <- rnorm(R, 0, mu.theta.sd)
priora2 <- mu1 > mu2 & mu3 > mu4
prior.prob.a2 <- mean(priora2)

#MA3
##Posterior
a3 <- est.u[,1] < est.u[,2] & est.u[,3] < est.u[,4]
post.prob.a3 <- mean(a3)

##Prior prob
priora3 <- mu1 < mu2 & mu3 < mu4
prior.prob.a3 <- mean(priora3)

#MA4
##Posterior
a4 <- est.u[,1] > est.u[,2] & est.u[,3] < est.u[,4]
post.prob.a4 <- mean(a4)

##Prior prob
priora4 <- mu1 > mu2 & mu3 < mu4
prior.prob.a4 <- mean(priora4)

#bfs everything compared to M0
bf.starbase <- log(post.prob.star / prior.prob.star) + out_star$bf
bf.a2base <- log(post.prob.a2 / prior.prob.a2) + out_u$bf
bf.a3base <- log(post.prob.a3 / prior.prob.a3) + out_u$bf
bf.a4base <- log(post.prob.a4 / prior.prob.a4) + out_u$bf
bf.staru <- exp(bf.starbase - out_u$bf)
bf.stara1 <- exp(bf.starbase - out_A1$bf)
bf.stara2 <- exp(bf.starbase - bf.a2base)
bf.stara3 <- exp(bf.starbase - bf.a3base)
bf.stara4 <- exp(bf.starbase - bf.a4base)

bfs.exp3 <- c('staru' = bf.staru, 'star1' = bf.stara1, 'star2' = bf.stara2, 'star3' = bf.stara3, 'star4' = bf.stara4)

```

```{r}
tabresExp3 <- tabres
dat.clean.3 <- dat.clean
props_subj_3 <- props_subj
freq_subj_3 <- freq_subj
I.3 <- I
L.3 <- L
```

